{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import scipy.io as io\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "plt.gray();\n",
    "import matplotlib.patheffects as pe\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import seaborn as sb\n",
    "from sklearn.manifold import TSNE \n",
    "from numpy import *\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "# from IPython.display import display\n",
    "# np.set_printoptions(suppress=True, threshold=np.nan)    #去除科学计数法\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False # 显示中文\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "train_data=torchvision.datasets.CIFAR10(root='./',train=True,\n",
    "                                        download=False,transform=transform)\n",
    "test_data=torchvision.datasets.CIFAR10(root='./',train=False,\n",
    "                                        download=False,transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniformData(X,Y,n):\n",
    "    n_per_class=int(n/10)\n",
    "    X_uniform=[]\n",
    "    Y_uniform=[]\n",
    "    for i in range(10):\n",
    "        Xi=X[Y[:,0] == i]\n",
    "        randIndices=[np.random.randint(0, Xi.shape[0]) for i in range(n_per_class)]\n",
    "        X_uniform.append(Xi[randIndices])\n",
    "        Yi=Y[(Y[:,0]==i)]\n",
    "        Y_uniform.append(Yi[randIndices])\n",
    "    X_uniform=np.vstack(np.array(X_uniform))\n",
    "    Y_uniform=np.vstack(np.array(Y_uniform))\n",
    "    return X_uniform, Y_uniform\n",
    "\n",
    "def rgb2gray(images):\n",
    "    return np.expand_dims(np.dot(images, [0.2990, 0.5870, 0.1140]), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(50000, 32, 32, 1) (50000, 1)\n",
      "(10000, 32, 32, 1) (10000, 1)\n",
      "(1000, 100) (1000, 1) (200, 100) (200, 1)\n",
      "0.9303927 0.97232157\n",
      "数字 0 , 第 1 轮 loss:  346.0402949840355 |w|.sum:  99.00363766127649 acc=  0.486\n",
      "数字 0 , 第 1 轮 loss:  280.1333567507494 |w|.sum:  98.00423823834325 acc=  0.492\n",
      "数字 0 , 第 1 轮 loss:  239.51450554219008 |w|.sum:  97.0050598163731 acc=  0.507\n",
      "数字 0 , 第 1 轮 loss:  130.5136115149717 |w|.sum:  88.02529486665824 acc=  0.509\n",
      "数字 0 , 第 1 轮 loss:  124.40915795157858 |w|.sum:  87.02900929910274 acc=  0.512\n",
      "数字 0 , 第 1 轮 loss:  115.1962582441023 |w|.sum:  85.03175869338946 acc=  0.513\n",
      "数字 0 , 第 1 轮 loss:  102.6175905386151 |w|.sum:  82.03428485009934 acc=  0.52\n",
      "数字 0 , 第 1 轮 loss:  59.32104486108912 |w|.sum:  62.10353093710428 acc=  0.529\n",
      "数字 0 , 第 1 轮 loss:  50.19580242656709 |w|.sum:  55.1317760888398 acc=  0.53\n",
      "数字 0 , 第 1 轮 loss:  43.98898405198839 |w|.sum:  49.16134139952153 acc=  0.532\n",
      "数字 0 , 第 1 轮 loss:  18.40142468058815 |w|.sum:  11.411155477957085 acc=  0.533\n",
      "数字 0 , 第 1 轮 loss:  14.290823680623825 |w|.sum:  0.47273373752600956 acc=  0.599\n",
      "数字 0 , 第 2 轮 loss:  14.290847290784715 |w|.sum:  0.47293254356991254 acc=  0.6\n",
      "数字 0 , 第 4 轮 loss:  14.29136070608068 |w|.sum:  0.4843093686399301 acc=  0.601\n",
      "数字 0 , 第 7 轮 loss:  14.291896336282885 |w|.sum:  0.4977787105853386 acc=  0.602\n",
      "数字 0 , 第 12 轮 loss:  14.292308358094251 |w|.sum:  0.508397928592969 acc=  0.603\n",
      "数字0训练完毕\n",
      "数字 1 , 第 1 轮 loss:  346.03338644932927 |w|.sum:  99.00080265530288 acc=  0.495\n",
      "数字 1 , 第 1 轮 loss:  280.11768866745007 |w|.sum:  98.00447326648819 acc=  0.515\n",
      "数字 1 , 第 1 轮 loss:  239.49882695935315 |w|.sum:  97.00481182615003 acc=  0.53\n",
      "数字 1 , 第 1 轮 loss:  51.308395304495725 |w|.sum:  56.18350687880936 acc=  0.531\n",
      "数字 1 , 第 1 轮 loss:  45.8772701302486 |w|.sum:  51.21539099449733 acc=  0.537\n",
      "数字 1 , 第 1 轮 loss:  18.401038120126643 |w|.sum:  11.570886753725556 acc=  0.538\n",
      "数字 1 , 第 1 轮 loss:  14.291748889188684 |w|.sum:  0.6838197450326684 acc=  0.612\n",
      "数字 1 , 第 2 轮 loss:  14.291780742746019 |w|.sum:  0.6841422408165496 acc=  0.613\n",
      "数字 1 , 第 3 轮 loss:  14.292297867300185 |w|.sum:  0.6932790285135604 acc=  0.614\n",
      "数字 1 , 第 5 轮 loss:  14.292548330478308 |w|.sum:  0.6984231748333672 acc=  0.615\n",
      "数字1训练完毕\n",
      "数字 2 , 第 1 轮 loss:  346.03516545322316 |w|.sum:  99.00076231569216 acc=  0.478\n",
      "数字 2 , 第 1 轮 loss:  239.51761177171323 |w|.sum:  97.003393779018 acc=  0.504\n",
      "数字 2 , 第 1 轮 loss:  162.2594369617875 |w|.sum:  92.01621658297134 acc=  0.505\n",
      "数字 2 , 第 1 轮 loss:  130.5241801811079 |w|.sum:  88.03079885697768 acc=  0.515\n",
      "数字 2 , 第 1 轮 loss:  119.36588380910123 |w|.sum:  86.03359632738557 acc=  0.517\n",
      "数字 2 , 第 1 轮 loss:  21.26685322036951 |w|.sum:  17.315672833745456 acc=  0.518\n",
      "数字 2 , 第 1 轮 loss:  20.785896407570362 |w|.sum:  16.33490149169066 acc=  0.527\n",
      "数字 2 , 第 1 轮 loss:  17.935808993129783 |w|.sum:  10.353375517403428 acc=  0.534\n",
      "数字 2 , 第 1 轮 loss:  15.983901574562632 |w|.sum:  5.3924549588378206 acc=  0.536\n",
      "数字 2 , 第 1 轮 loss:  14.294312965580875 |w|.sum:  0.42913604023346963 acc=  0.574\n",
      "数字2训练完毕\n",
      "数字 3 , 第 1 轮 loss:  346.03243302420327 |w|.sum:  99.0021380719372 acc=  0.506\n",
      "数字 3 , 第 1 轮 loss:  239.51595328364687 |w|.sum:  97.005702986981 acc=  0.524\n",
      "数字 3 , 第 1 轮 loss:  14.29669503391126 |w|.sum:  0.5054239509876648 acc=  0.584\n",
      "数字 3 , 第 4 轮 loss:  14.29717814086842 |w|.sum:  0.5166556285196804 acc=  0.585\n",
      "数字 3 , 第 5 轮 loss:  14.297374687229787 |w|.sum:  0.5203172283015725 acc=  0.586\n",
      "数字3训练完毕\n",
      "数字 4 , 第 1 轮 loss:  346.03270443722215 |w|.sum:  99.00167551631344 acc=  0.513\n",
      "数字 4 , 第 1 轮 loss:  239.51661765774244 |w|.sum:  97.00455778577175 acc=  0.518\n",
      "数字 4 , 第 1 轮 loss:  162.25503415911223 |w|.sum:  92.01202495261111 acc=  0.522\n",
      "数字 4 , 第 1 轮 loss:  143.62040092604698 |w|.sum:  90.01315030625659 acc=  0.525\n",
      "数字 4 , 第 1 轮 loss:  102.61924286884333 |w|.sum:  82.02249498902258 acc=  0.527\n",
      "数字 4 , 第 1 轮 loss:  66.37644842749218 |w|.sum:  67.06939899876713 acc=  0.529\n",
      "数字 4 , 第 1 轮 loss:  59.317212415426155 |w|.sum:  62.096652803150995 acc=  0.535\n",
      "数字 4 , 第 1 轮 loss:  14.266117036903507 |w|.sum:  0.37493467879554554 acc=  0.57\n",
      "数字4训练完毕\n",
      "数字 5 , 第 1 轮 loss:  346.0334724840451 |w|.sum:  99.00070935553326 acc=  0.511\n",
      "数字 5 , 第 1 轮 loss:  239.52153173864016 |w|.sum:  97.00679840120651 acc=  0.522\n",
      "数字 5 , 第 1 轮 loss:  143.617902480987 |w|.sum:  90.02579272187916 acc=  0.524\n",
      "数字 5 , 第 1 轮 loss:  130.51097585759328 |w|.sum:  88.02771552261902 acc=  0.531\n",
      "数字 5 , 第 1 轮 loss:  18.380591973256607 |w|.sum:  11.439646016035763 acc=  0.532\n",
      "数字 5 , 第 1 轮 loss:  17.90625975572246 |w|.sum:  10.44424155801006 acc=  0.54\n",
      "数字 5 , 第 1 轮 loss:  14.270806053350322 |w|.sum:  0.5028922499778368 acc=  0.586\n",
      "数字 5 , 第 2 轮 loss:  14.270844917568025 |w|.sum:  0.5045577103918658 acc=  0.587\n",
      "数字 5 , 第 3 轮 loss:  14.270903861021857 |w|.sum:  0.5086781882584079 acc=  0.588\n",
      "数字 5 , 第 3 轮 loss:  14.270957877439427 |w|.sum:  0.5119334848569405 acc=  0.589\n",
      "数字 5 , 第 6 轮 loss:  14.271145576331023 |w|.sum:  0.5210221358823709 acc=  0.59\n",
      "数字 5 , 第 8 轮 loss:  14.271285153319099 |w|.sum:  0.528127690282166 acc=  0.591\n",
      "数字 5 , 第 10 轮 loss:  14.27139528427092 |w|.sum:  0.5330933668403435 acc=  0.592\n",
      "数字 5 , 第 13 轮 loss:  14.271540051756217 |w|.sum:  0.5403933786570401 acc=  0.593\n",
      "数字 5 , 第 15 轮 loss:  14.271611210977253 |w|.sum:  0.5434412926120187 acc=  0.594\n",
      "数字5训练完毕\n",
      "数字 6 , 第 1 轮 loss:  346.0324075914452 |w|.sum:  99.00218773237454 acc=  0.508\n",
      "数字 6 , 第 1 轮 loss:  239.51423524561633 |w|.sum:  97.00406456327886 acc=  0.51\n",
      "数字 6 , 第 1 轮 loss:  59.30560891897357 |w|.sum:  62.09297027143987 acc=  0.511\n",
      "数字 6 , 第 1 轮 loss:  52.65846115313172 |w|.sum:  57.10889288446473 acc=  0.512\n",
      "数字 6 , 第 1 轮 loss:  51.30682391639922 |w|.sum:  56.11574031939864 acc=  0.515\n",
      "数字 6 , 第 1 轮 loss:  24.544320930978415 |w|.sum:  23.25753691341508 acc=  0.516\n",
      "数字 6 , 第 1 轮 loss:  20.74541938925359 |w|.sum:  16.288659741689884 acc=  0.518\n",
      "数字 6 , 第 1 轮 loss:  19.777283926810732 |w|.sum:  14.290776621314642 acc=  0.522\n",
      "数字 6 , 第 1 轮 loss:  19.259715409862274 |w|.sum:  13.302660864163279 acc=  0.524\n",
      "数字 6 , 第 1 轮 loss:  18.368902642487868 |w|.sum:  11.312388080789177 acc=  0.527\n",
      "数字 6 , 第 1 轮 loss:  17.89453849112977 |w|.sum:  10.316398803781086 acc=  0.533\n",
      "数字 6 , 第 1 轮 loss:  14.252944132622922 |w|.sum:  0.34515010913569194 acc=  0.569\n",
      "数字 6 , 第 2 轮 loss:  14.252931021826004 |w|.sum:  0.34577414348702545 acc=  0.57\n",
      "数字6训练完毕\n",
      "数字 7 , 第 1 轮 loss:  346.0348554669656 |w|.sum:  99.00052943044236 acc=  0.478\n",
      "数字 7 , 第 1 轮 loss:  239.52003928935665 |w|.sum:  97.00612872412984 acc=  0.513\n",
      "数字 7 , 第 1 轮 loss:  162.2573097243823 |w|.sum:  92.0176090716885 acc=  0.514\n",
      "数字 7 , 第 1 轮 loss:  143.6177450512095 |w|.sum:  90.02523324453959 acc=  0.518\n",
      "数字 7 , 第 1 轮 loss:  130.50922507530927 |w|.sum:  88.0297645959419 acc=  0.521\n",
      "数字 7 , 第 1 轮 loss:  124.40537841614226 |w|.sum:  87.03027157913613 acc=  0.524\n",
      "数字 7 , 第 1 轮 loss:  115.18393249237789 |w|.sum:  85.04276265118149 acc=  0.526\n",
      "数字 7 , 第 1 轮 loss:  102.60194153682201 |w|.sum:  82.05813069501002 acc=  0.54\n",
      "数字 7 , 第 1 轮 loss:  21.19366950725734 |w|.sum:  17.448754608361863 acc=  0.543\n",
      "数字 7 , 第 1 轮 loss:  20.712366460047 |w|.sum:  16.448881593157182 acc=  0.55\n",
      "数字 7 , 第 1 轮 loss:  14.217992225495166 |w|.sum:  0.5731759257862137 acc=  0.594\n",
      "数字 7 , 第 2 轮 loss:  14.217845139389501 |w|.sum:  0.5762430349382852 acc=  0.595\n",
      "数字 7 , 第 4 轮 loss:  14.21760714837512 |w|.sum:  0.5870576818478024 acc=  0.596\n",
      "数字 7 , 第 8 轮 loss:  14.217304888768115 |w|.sum:  0.5987547226513886 acc=  0.597\n",
      "数字 7 , 第 9 轮 loss:  14.217227930782647 |w|.sum:  0.6030608354963765 acc=  0.598\n",
      "数字 7 , 第 12 轮 loss:  14.217080764414234 |w|.sum:  0.6093192011148629 acc=  0.599\n",
      "数字7训练完毕\n",
      "数字 8 , 第 1 轮 loss:  346.03680791033383 |w|.sum:  99.001841302261 acc=  0.494\n",
      "数字 8 , 第 1 轮 loss:  280.11877287113464 |w|.sum:  98.0064094245723 acc=  0.516\n",
      "数字 8 , 第 1 轮 loss:  21.189214446509492 |w|.sum:  17.312710727543084 acc=  0.52\n",
      "数字 8 , 第 1 轮 loss:  20.161882984936906 |w|.sum:  15.313723150335289 acc=  0.523\n",
      "数字 8 , 第 1 轮 loss:  19.222164701849056 |w|.sum:  13.32854991800276 acc=  0.525\n",
      "数字 8 , 第 1 轮 loss:  18.85827640213899 |w|.sum:  12.32880843263284 acc=  0.528\n",
      "数字 8 , 第 1 轮 loss:  18.33196509701954 |w|.sum:  11.33001425290081 acc=  0.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数字 8 , 第 1 轮 loss:  17.856960428906373 |w|.sum:  10.339226114109891 acc=  0.541\n",
      "数字 8 , 第 1 轮 loss:  14.211664134652665 |w|.sum:  0.4484935345607652 acc=  0.61\n",
      "数字 8 , 第 2 轮 loss:  14.211606200242972 |w|.sum:  0.45147334940252376 acc=  0.611\n",
      "数字 8 , 第 3 轮 loss:  14.2114805388373 |w|.sum:  0.4556698146043569 acc=  0.612\n",
      "数字 8 , 第 3 轮 loss:  14.211463723897662 |w|.sum:  0.45629117328683144 acc=  0.613\n",
      "数字8训练完毕\n",
      "数字 9 , 第 1 轮 loss:  346.0351393587786 |w|.sum:  99.00074315974649 acc=  0.478\n",
      "数字 9 , 第 1 轮 loss:  280.11410851511465 |w|.sum:  98.00652332301726 acc=  0.494\n",
      "数字 9 , 第 1 轮 loss:  239.49582239697892 |w|.sum:  97.01018294683976 acc=  0.529\n",
      "数字 9 , 第 1 轮 loss:  185.35837880744228 |w|.sum:  94.01771184142903 acc=  0.531\n",
      "数字 9 , 第 1 轮 loss:  93.07571202206539 |w|.sum:  79.05946317329 acc=  0.54\n",
      "数字 9 , 第 1 轮 loss:  14.170895048025132 |w|.sum:  0.5472458783050526 acc=  0.622\n",
      "数字 9 , 第 2 轮 loss:  14.170892515252106 |w|.sum:  0.5472508024949142 acc=  0.623\n",
      "数字9训练完毕\n",
      "训练集\n",
      "最大式多分类总和准确率：0.243\n",
      "每个类上的准确率： [0.601, 0.613, 0.572, 0.581, 0.567, 0.594, 0.57, 0.597, 0.61, 0.619] 迭代式应得准确率： 0.14646323479189166 每个类上的auc:  [0.7338888888888888, 0.7494444444444444, 0.691111111111111, 0.6916666666666668, 0.715, 0.7122222222222222, 0.7033333333333334, 0.7005555555555556, 0.7611111111111111, 0.775]\n",
      "迭代式多分类总和准确率：0.193\n",
      "\n",
      "测试集\n",
      "最大式多分类总和准确率：0.09\n",
      "每个类上的准确率： [0.535, 0.515, 0.48, 0.535, 0.49, 0.495, 0.515, 0.42, 0.57, 0.525] 迭代式应得准确率： 0.10811402275563009 每个类上的auc:  [0.5416666666666667, 0.5083333333333333, 0.4444444444444444, 0.586111111111111, 0.49444444444444446, 0.49722222222222223, 0.5305555555555556, 0.3666666666666667, 0.6944444444444444, 0.5805555555555555]\n",
      "迭代式多分类总和准确率：0.105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.105"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THREASHOLD=0.5\n",
    "n=1000\n",
    "n_test=200\n",
    "dopca=1\n",
    "\n",
    "X=train_data.data\n",
    "y=np.array(train_data.targets)[:, np.newaxis]\n",
    "X_test=test_data.data\n",
    "y_test=np.array(test_data.targets)[:, np.newaxis]\n",
    "print(X.shape,y.shape,X_test.shape,y_test.shape)\n",
    "print(np.unique(y))\n",
    "\n",
    "X = rgb2gray(X).astype(np.float32)\n",
    "X, y = getUniformData(X,y,n)\n",
    "X=X.reshape(n,-1)  \n",
    "X_mean = np.mean(X, axis=0)  # 第一维变化，对其他维每个位置上求均值和方差\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "if dopca:\n",
    "    pca = PCA(n_components=100)\n",
    "    pca.fit(X)                  #训练\n",
    "    X=pca.fit_transform(X)   #降维后的数据\n",
    "d=X.shape[1]\n",
    "\n",
    "X_test = rgb2gray(X_test).astype(np.float32)\n",
    "X_test, y_test = getUniformData(X_test, y_test,n_test)\n",
    "X_test=X_test.reshape(n_test,-1)\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "if dopca:\n",
    "    pca_test = PCA(n_components=d)\n",
    "    pca_test.fit(X_test)                  #训练\n",
    "    X_test=pca_test.fit_transform(X_test)   #降维后的数据\n",
    "\n",
    "print(X.shape,y.shape,X_test.shape,y_test.shape)\n",
    "print(np.sum(pca.explained_variance_ratio_),np.sum(pca_test.explained_variance_ratio_))\n",
    "\n",
    "class LogsiticRegression(object):\n",
    "    w = None # 权重\n",
    "    W = None\n",
    "    n = 0 # 样本个数\n",
    "    d = 0 # 维度个数\n",
    "    learning_rate = 0.01\n",
    "    loss_difference = 0.001 # loss 改变的百分比\n",
    "    loss_bound = 0.3\n",
    "    num_labels = 10\n",
    "    plambda = 0.2 # 正则参数\n",
    "    \n",
    "    def __init__(self,*args, **kwargs):\n",
    "        self.f=open('output.txt', \"w\",encoding='utf-8')\n",
    "        \n",
    "    def sigmoid(self,xb): # xb 是列向量\n",
    "#         s=np.ones((len(xb),1))   \n",
    "#         s=1.0/(1.0+np.exp(-xb))\n",
    "#         return s\n",
    "        return 1.0 / (1.0 + np.exp(-xb))\n",
    "\n",
    "    def loss(self,X,Y):\n",
    "        Xw=self.sigmoid(np.dot(X,self.w))\n",
    "#         w2=self.w.copy()  \n",
    "#         w2[0]=0           \n",
    "        Loss=-(np.dot(Y.transpose(),np.log(Xw))+np.dot(np.transpose(1-Y),np.log(1-Xw)))/self.n # Xw里有1导致log 0\n",
    "        #+(plambda*np.dot(np.transpose(w2),w2))/(2*self.n) \n",
    "        return Loss[0][0]\n",
    "    \n",
    "    # 课件1 P4 简化公式\n",
    "    def loss2(self,X,Y):\n",
    "        Xw=np.dot(X,self.w) \n",
    "#         w2=w.copy()  \n",
    "#         w2[0]=0           \n",
    "        Loss=(np.sum(np.log(1+np.exp(Xw)))-np.dot(Y.transpose(),Xw))/self.n\n",
    "        #+(plambda*np.dot(np.transpose(w2),w2))/(2*self.n) \n",
    "        return Loss[0][0]\n",
    "    \n",
    "    # 逐个样本计算,去除异常值\n",
    "    def loss3(self,X,Y):\n",
    "        sum_err = 0.0\n",
    "        Xw=self.sigmoid(np.dot(X,self.w))  #  Bug： 一直没加sigmoid！！！\n",
    "        for i in range(self.n):\n",
    "            if Xw[i][0] > 0 and Xw[i][0] < 1:\n",
    "                sum_err -= (Y[i][0] * np.log(Xw[i][0]) + (1-Y[i][0]) * np.log(1-Xw[i][0]))\n",
    "        return sum_err / self.n\n",
    "    \n",
    "    def loss4(self,w,X,Y,initial_lambda):\n",
    "        n=len(Y)\n",
    "        h=1.0/(1.0+np.exp(-np.dot(X,w)))\n",
    "#         theta1=w.copy()    \n",
    "#         theta1[0]=0         \n",
    "        J=-(np.dot(np.transpose(Y),np.log(h))+np.dot(np.transpose(1-Y),np.log(1-h)))/self.n #+(initial_lambda*np.dot(np.transpose(theta1),theta1))/(2*n)\n",
    "        return J\n",
    "    \n",
    "    def loss5_ridge(self,X,Y):\n",
    "        y_Xw=Y-np.dot(X,self.w)\n",
    "        return (np.dot(y_Xw.transpose(),y_Xw)[0][0]+self.plambda*np.dot(self.w.transpose(),self.w)[0][0])/self.n\n",
    "\n",
    "    def loss6_lasso(self,X,Y):\n",
    "        y_Xw=Y-np.dot(X,self.w)\n",
    "        return (np.dot(y_Xw.transpose(),y_Xw)[0][0]/2+self.plambda*np.sum(abs(self.w)))/self.n\n",
    "    \n",
    "    def gradient(self,X,Y):\n",
    "#         g=np.zeros((self.d))\n",
    "        hx=self.sigmoid(np.dot(X,self.w))    #调用sigmoid函数\n",
    "        w2=self.w.copy()\n",
    "        w2[0]=0            \n",
    "        g=np.dot(np.transpose(X),hx-Y)+self.plambda*w2#/self.n # 加第二项就是ridge logistic regression\n",
    "        return g\n",
    "    \n",
    "    def gradient2(self,w,X,Y,initial_lambda):\n",
    "#         g=np.zeros((self.d))\n",
    "        n=X.shape[0]\n",
    "        hx=self.sigmoid(np.dot(X,w))\n",
    "#         w2=w.copy()\n",
    "#         w2[0]=0            \n",
    "        g=np.dot(np.transpose(X),hx-Y)/n\n",
    "        #+initial_lambda*w2/n\n",
    "        return g\n",
    "    \n",
    "    def gradient5_ridge(self,X,Y):\n",
    "        # −2X(Y −Xˆβλ) + 2λˆβλ.\n",
    "        a=np.dot(X.transpose(),Y-np.dot(X,self.w))\n",
    "#         print(a[0:20])\n",
    "        return -2*a/np.max(a)+2*self.plambda*self.w\n",
    "         \n",
    "    def train(self,X,Y):\n",
    "        self.n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        y_class=np.zeros((X.shape[0],1))  # 第i个样本是不是数字j\n",
    "        self.W = np.zeros((X.shape[1],self.num_labels))\n",
    "        \n",
    "        for i in range(self.num_labels):\n",
    "            count = 1\n",
    "            new_loss=0\n",
    "            self.learning_rate=0.01\n",
    "            self.w = np.full((self.d,1),1/self.d) # np.zeros((X.shape[1],1))\n",
    "            y_class[:,0]=np.int32(Y==i).reshape(1,-1) # 行向量赋给列向量\n",
    "            acc=0\n",
    "            w_max = np.full((self.d,1),1/self.d)\n",
    "            acc_max=0\n",
    "            while True:\n",
    "                old_loss = new_loss\n",
    "                self.w = self.w - self.learning_rate * self.gradient(X,y_class)#/np.max(self.w) # gradient5_ridge\n",
    "                acc,aoc=self.prediect_one_class(X,y_class)\n",
    "                \n",
    "#                 self.w=self.w/np.max(self.w)\n",
    "                new_loss = self.loss3(X, y_class) # loss3 loss5_ridge\n",
    "                if acc>0.8 or count>500 or (new_loss < self.loss_bound and math.fabs(old_loss - new_loss)/max(self.loss_bound,new_loss) < self.loss_difference):\n",
    "                    print(\"第\"+str(i)+\"个分类器训练完毕, \",\"收敛到:\",new_loss)\n",
    "#                     self.f.write(\"第\"+str(i)+\"个分类器训练完毕\\n收敛到:\"+str(new_loss)+\"\\n\")\n",
    "                    break\n",
    "                if acc>acc_max:\n",
    "                    acc_max=acc\n",
    "                    w_max=self.w\n",
    "                    print(\"训练数字\"+str(i)+\" 迭代第\",count,\"次, loss=\",new_loss,\"acc_max=\",acc_max,\"大w个数 \",np.sum(self.w>1000000000))\n",
    "#                     print(self.w[0:10,0])\n",
    "                    \n",
    "#                     print(self.w)\n",
    "#                 self.f.write(\"训练数字\"+str(i)+\" 迭代第\"+str(count)+\"次!\\n\"+str(old_loss)+'\\n'+str(new_loss)+'\\n')\n",
    "#                 print(\"损失减小:\",(old_loss - new_loss))\n",
    "#                 print(old_loss)\n",
    "                count += 1\n",
    "                self.learning_rate=self.learning_rate*0.99\n",
    "                \n",
    "            print(\"数字\"+str(i)+\"训练完毕\")\n",
    "#             self.f.write(\"数字\"+str(i)+\"训练完毕\\n\")\n",
    "            self.W[:,i]=w_max[:,0]\n",
    "#             self.W[:,i]=self.W[:,i-1]/np.max(self.W[:,i-1])\n",
    " \n",
    "    def train_Lasso(self,X,Y):\n",
    "        self.n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        y_class=np.zeros((X.shape[0],1))  # 第i个样本是不是数字j\n",
    "        self.W = np.zeros((X.shape[1],self.num_labels))\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_labels):\n",
    "            count = 1\n",
    "            new_loss=0\n",
    "            delta=1\n",
    "            self.w = np.full((self.d,1),1.0) # np.zeros((X.shape[1],1))\n",
    "            y_class[:,0]=np.int32(Y==i).reshape(1,-1) # 行向量赋给列向量\n",
    "            acc=0\n",
    "            R = np.full((self.n,self.d),0.1)\n",
    "            r = np.full((self.d,1),0.01)\n",
    "            w_max = np.full((self.d,1),1.0)\n",
    "            acc_max=0\n",
    "            for q in range(1,21):\n",
    "                for j in range(self.d):\n",
    "                    w=self.w.copy()\n",
    "                    w[j][0]=0\n",
    "                    R[:,j]=(y_class-np.dot(X,w))[:,0]\n",
    "                    xx=np.sum(np.dot(X[:,j],X[:,j]))\n",
    "                    r[j][0]=np.sum(np.dot(R[:,j],X[:,j]))/xx\n",
    "#                     print(r[j][0])\n",
    "#                     print(delta/xx)\n",
    "                    self.w[j][0]=r[j][0]/abs(r[j][0])*max(0,abs(r[j][0])-delta/xx)\n",
    "                    acc,aoc=self.prediect_one_class(X,y_class)\n",
    "                    if acc_max<acc:\n",
    "                        acc_max=acc\n",
    "                        w_max=self.w\n",
    "                        print(\"数字\",i,\", 第\",q,\"轮 loss: \",self.loss6_lasso(X,Y),\"|w|.sum: \",np.sum(abs(self.w)),\"acc= \",acc)\n",
    "                #self.w=self.w/np.max(self.w)\n",
    "                delta=delta*0.9\n",
    "\n",
    "                    \n",
    "            self.W[:,i]=w_max[:,0]\n",
    "            print(\"数字\"+str(i)+\"训练完毕\")\n",
    "\n",
    "    # 多分类 同时预测每个类的准确率，选最大值\n",
    "    def predict(self,X_test,y_test):\n",
    "        y_predict = self.sigmoid(np.dot(X_test,self.W))\n",
    "        y_class = np.zeros((X_test.shape[0],1))\n",
    "        for i in range(X_test.shape[0]):\n",
    "#             max_class=0\n",
    "#             for j in range(self.num_labels):\n",
    "#                 if y_predict[i][j] >0.5:\n",
    "            max_class=0\n",
    "            for j in range(1,self.num_labels):\n",
    "                if y_predict[i][j] >y_predict[i][max_class]:\n",
    "                    max_class=j\n",
    "                    break\n",
    "            y_class[i][0]=max_class\n",
    "        result = (y_test==y_class)\n",
    "        print(\"最大式多分类总和准确率：\"+str(np.sum(result)/len(result)))\n",
    "#         print(\"auc: \", roc_auc_score(y_test, y_predict,average='macro'))#multi_class='ovo',average='weighted'\n",
    "        \n",
    "#         self.f.write(\"准确率：\"+str(np.sum(result)/len(result))+'\\n')\n",
    "        return np.sum(result)/len(result)\n",
    "\n",
    "    # 二分类 输入为向量\n",
    "    def prediect_one_class(self,X,Y): \n",
    "        y_predict = self.sigmoid(np.dot(X,self.w))\n",
    "        y_class = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if y_predict[i][0]>THREASHOLD:\n",
    "                y_class[i][0]=1\n",
    "        result = (Y==y_class)\n",
    "        acc=np.sum(result)/len(result)\n",
    "        return acc,roc_auc_score(Y,y_class)\n",
    "    \n",
    "    # 二分类 逐个预测每个类的准确率\n",
    "    def predict2(self,X,Y):\n",
    "        y_class = np.zeros((X.shape[0],1)) # 预测出是不是类i\n",
    "        Y_class = np.zeros((X.shape[0],1)) # 真实类是不是类i\n",
    "        acc=[]\n",
    "        auc=[]\n",
    "        for i in range(self.num_labels):      \n",
    "            y_predict = self.sigmoid(np.dot(X,self.W[:,i]))[:, np.newaxis] # 扩充一维\n",
    "            y_class = np.zeros((X.shape[0],1))\n",
    "            for j in range(X.shape[0]):\n",
    "                if y_predict[j][0]>THREASHOLD:\n",
    "                    y_class[j][0]=1\n",
    "            Y_class[:,0]=np.int32(Y==i).reshape(1,-1) # 行向量赋给列向量\n",
    "            result = (Y_class==y_class)\n",
    "            acc.append(np.sum(result)/len(result))\n",
    "            auc.append(roc_auc_score(Y_class,y_class))\n",
    "        \n",
    "        wish_acc=0\n",
    "        t=1\n",
    "        for i in range(10):\n",
    "            wish_acc+=t*acc[i]\n",
    "            t*=acc[i]\n",
    "        \n",
    "        print(\"每个类上的准确率：\",acc,\"迭代式应得准确率：\",wish_acc/10,\"每个类上的auc: \",auc)     \n",
    "\n",
    "    # 多分类 同时预测每个类的准确率, 迭代判断\n",
    "    def predict3(self,X,Y):\n",
    "        y_predict = self.sigmoid(np.dot(X,self.W))\n",
    "        y_class = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            max_class=0\n",
    "            for j in range(self.num_labels):\n",
    "                if y_predict[i][j] >THREASHOLD:\n",
    "#             max_class=1\n",
    "#             for j in range(1,self.num_labels):\n",
    "#                 if y_predict[i][j] >y_predict[i][max_class]:\n",
    "                    max_class=j\n",
    "                    break\n",
    "            y_class[i][0]=max_class\n",
    "        result = (Y==y_class)\n",
    "        print(\"迭代式多分类总和准确率：\"+str(np.sum(result)/len(result)))\n",
    "#         print(\"auc: \",roc_auc_score(Y,y_predict,multi_class='ovo'))\n",
    "#         self.f.write(\"准确率：\"+str(np.sum(result)/len(result))+'\\n')\n",
    "        return np.sum(result)/len(result)\n",
    "    \n",
    "    def save_W(self):\n",
    "        with open('W.npy', 'wb') as f:\n",
    "            np.save(f, self.W)\n",
    "            f.close()\n",
    "    def load_W(self):\n",
    "        with open('W.npy', 'rb') as f:\n",
    "            self.W = np.load(f)\n",
    "            f.close()\n",
    "        np.savez('./model.npz', L0_W = session.run(L0_W), L0_B = session.run(L0_B))\n",
    "        \n",
    "lr = LogsiticRegression()\n",
    "# lr.train(X,y)\n",
    "lr.train_Lasso(X,y)\n",
    "print(\"训练集\")\n",
    "lr.predict(X,y)\n",
    "lr.predict2(X,y)\n",
    "lr.predict3(X,y)\n",
    "print(\"\\n测试集\")\n",
    "lr.predict(X_test,y_test)\n",
    "lr.predict2(X_test,y_test)\n",
    "lr.predict3(X_test,y_test)\n",
    "# lr.save_W()\n",
    "# lr.f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
